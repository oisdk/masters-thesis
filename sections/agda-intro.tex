\section{Programming and Proving in Cubical Agda} \label{agda-intro} Agda \citep{norellDependentlyTypedProgramming2008} is a dependently-typed, pure,
functional programming language and proof assistant.
In this section we will introduce the language with some basic examples, and
explain a little about how to program and prove in Agda.
Some Haskell knowledge will help, as much of the syntax (any many concepts) are
similar, but it is possible to struggle through without it.
It is recommended to try out the code examples in your own editor, or to look at
them in the real Agda files in the source.
The source is rendered and structured to be read alongside this document: it can
be found at \mbox{\url{https://doisinkidney.com/code/masters-thesis/README.html}}.

Agda is first and foremost a functional programming language, similar in syntax
and design to Haskell.
It is pure, meaning that it doesn't allow undeclared side effects, and
\emph{lazy}, meaning that expressions are not evaluated until they are needed
(although this has no effect on Agda's semantics: since Agda is total, both lazy
and strict evaluation will result in the same output).

While Agda can be compiled (to Haskell, or to JavaScript), it is usually just
type-checked: this is because Agda is also a \emph{proof assistant}.
Programs written in Agda correspond to proofs in the formal language of
Martin-LÃ¶f Type Theory \citep{martin-lofIntuitionisticTypeTheory1980}, in the
style of ``Propositions as Types'' \citep{wadlerPropositionsTypes2015}.
Types in Agda correspond to formal propositions; the programs which inhabit
those types correspond to proofs of those propositions.
\begin{figure}
  \centering
  \begin{tikzcd}
    \text{Proposition} \ar[r, leftrightsquigarrow] & \text{Type} \\
    \text{Proof} \ar[r, leftrightsquigarrow] \ar[u, "\text{proves}"
    description]& \text{Program} \ar[u, "\text{inhabits}" description]
  \end{tikzcd}
\end{figure}
\subsection{Basic Functional Programming in Agda}
The basic unit of functionality in Agda is the \emph{type}.
Let's define a type: the type of booleans (we include the equivalent code in
Haskell on the right).
\begin{agdalisting} \label{bool-def}
  \begin{multicols}{2} \centering
    \ExecuteMetaDataInline[agda/Snippets/Bool.tex]{bool-def} \columnbreak
    \ExecuteMetaDataInline[haskell/Bool.tex]{bool-def}
  \end{multicols}\vspace{-2\baselineskip}
\end{agdalisting}
There's a lot of syntax wrapped up in this small snippet.
In prose, it provides four basic pieces of information:
\begin{samepage}
\begin{enumerate}
  \item We are defining a new \AgdaKeyword{data} type.
  \item Its name is \AgdaDatatype{Bool}.
  \item \AgdaDatatype{Bool} is a \AgdaFunction{\(\text{Type}_0\)} kind of thing.
  \item There are two ways to construct values of type \AgdaDatatype{Bool}:
    \AgdaInductiveConstructor{false} and \AgdaInductiveConstructor{true}.
\end{enumerate}
\end{samepage}
Let's explain each piece one by one.

\paragraph{Data Types}
We first say that we're defining a new \AgdaKeyword{data} type.
Using the ``\AgdaKeyword{data}'' keyword is just one of the many ways of
defining types: it basically means that we are going to define the type by
listing all of its constructors (all of the ways to construct values of the
type).
There are other ways to define types: with the \AgdaKeyword{record} keyword, for
instance, which we'll see later; or we can define types by referencing other
types, creating a synonym.
Here, for instance, we define the \AgdaFunction{Boolean} type:
\begin{agdalisting*}
  \begin{multicols}{2} \centering
    \ExecuteMetaDataInline[agda/Snippets/Bool.tex]{boolean} \columnbreak
    \ExecuteMetaDataInline[haskell/Bool.tex]{boolean-synonym}
  \end{multicols}\vspace{-\baselineskip}
\end{agdalisting*}
This snippet says ``I am defining a new thing called \AgdaFunction{Boolean}, it
is a \AgdaFunction{\(\text{Type}_0\)}, and it is equal to \AgdaDatatype{Bool}''.
Of course this isn't a very interesting declaration: as the equals sign implies,
\AgdaFunction{Boolean} is the same as \AgdaFunction{Bool} (other than the
spelling).
We've basically defined a synonym for the old type.

Notice that in Haskell we needed a special keyword in order to define this type
synonym: in Agda, types are first-class values, which we can manipulate just as
we would functions or numbers.
As such, defining a type synonym is exactly the same as defining a new variable:
it doesn't need any special syntax.
\paragraph{Type Names}
The second point is pretty straightforward: the name of the type we've defined
is \AgdaDatatype{Bool}.
The only thing to watch out for here is that Agda has relatively few
restrictions on type names, unlike, say, Haskell.
This type could have included Unicode symbols (Agda supports roughly 50 Unicode
mathematical symbols), it could have started with a lowercase letter, etc.

\paragraph{Type\textsubscript{0}}
The third point is the most interesting: we say that \AgdaDatatype{Bool} is a
``\AgdaFunction{\(\text{Type}_0\)}'' kind of thing.
What does this mean?

Well, we've seen that we can assign types to variables just as easily as we
might assign values to variables: this is what was happening in the
\AgdaFunction{Boolean} example.
In fact, in Agda, there is no real distinction between ``types'' and ``values'':
types like \AgdaDatatype{Bool} \emph{are} values, just as much as
\AgdaInductiveConstructor{true} or \AgdaInductiveConstructor{false}!
This means that our types must themselves have types: hence we say that
\AgdaFunction{Boolean} has type \AgdaFunction{\(\text{Type}_0\)}.

But why the subscript 0?
Well we know that types are values in Agda, and so they themselves have types.
We know that the type of \AgdaDatatype{Bool} is
\AgdaFunction{\(\text{Type}_0\)}.
But what's the type of \AgdaFunction{\(\text{Type}_0\)}?
It turns out that if we say:
\begin{agdalisting*}
  \(\AgdaFunction{\(\text{Type}_0\)} :  \AgdaFunction{\(\text{Type}_0\)}\)
\end{agdalisting*}
We actually introduce a paradox into the language: Girard's paradox
\citep{girardInterpretationFonctionelleElimination1972}.
This is the type-theoretic analogue of Russell's paradox, and, if present, it
would allow us to prove things that are not true.
So we disallow it.

Dependently-types programming languages have many different ways of resolving
the issue: Agda's approach is called \emph{universe polymorphism}.
Basically, we say that the type of \AgdaInductiveConstructor{true} is
\AgdaDatatype{Bool}, the type of \AgdaDatatype{Bool} is
\AgdaFunction{\(\text{Type}_0\)}, the type of \AgdaFunction{\(\text{Type}_0\)}
is \AgdaFunction{\(\text{Type}_1\)}, the type of \AgdaFunction{\(\text{Type}_1\)}
is \AgdaFunction{\(\text{Type}_2\)}, and so on.

To be honest, avoiding Girard's paradox is one of things that isn't done
especially well in dependently-typed languages: most approaches require quite a
bit of tedious busywork from the programmer, and it's quite rare that a
programmer would run into a genuine universe size issue that exposes a deep
logical impossibility (we will run into one of the few cases in this thesis).
Most of the time, managing universe levels amounts to bookkeeping.
For that reason, and also because the current system of universe polymorphism in
Agda is quite under flux and likely to be changed soon, we won't spend too much
time on the topic.
Every code example provided is as universe-polymorphic as possible, though.

\paragraph{Constructors}
The last point is the simplest: we have listed the ways to construct values of
type \AgdaDatatype{Bool}.
Two ways, in fact, \AgdaInductiveConstructor{true} and
\AgdaInductiveConstructor{false}, and they're called the constructors.
We can use these constructors in programs by (for instance) assigning them to
variables.
\begin{multicols}{2}\centering
  \ExecuteMetaDataInline[agda/Snippets/Bool.tex]{bool-val}\columnbreak
  \ExecuteMetaDataInline[haskell/Bool.tex]{bool-val}
\end{multicols}\vspace{-2\baselineskip}\noindent
Here we've declared a variable\footnotemark\;called \AgdaFunction{a-boolean} with
the type \AgdaDatatype{Bool}, and said it is equal to the value
\AgdaInductiveConstructor{true}.

\footnotetext{Note that although we use the term ``variable'', the value of the
  variable \AgdaFunction{a-boolean} can not change.
  We couldn't reassign it on the following line.}

\subsection{Some Functions}
That's quite a lot of information on how to define things in Agda: let's look a
little about how to do computation.
What we need is a function:
\begin{multicols}{2}\centering
  \ExecuteMetaDataInline[agda/Snippets/Bool.tex]{not-def}\columnbreak
  \ExecuteMetaDataInline[haskell/Bool.tex]{not-func}
\end{multicols}\vspace{-2\baselineskip}\noindent
This function is defined by pattern-matching: when the clause on the
left-hand-side of the equals sign is seen, the right-hand-side is what's
computed.

This syntax with the equals sign is actually just syntactic sugar for a \(\lambda\).
The identity function, for instance, could be written as follows:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Implicits.tex]{id-lambda}
\end{agdalisting*}
The \AgdaFunction{not} function could also have been written with a \(\lambda\).
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Bool.tex]{lambda-not}
\end{agdalisting*}


For a more complex example, we're going to need a more complex type:
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Nat.tex]{nat-def}
\end{agdalisting}
This is the type of the natural numbers.
With \AgdaDatatype{Bool} (\Cref{bool-def}) we were able to list all the
actual values in the type: doing so for the natural numbers would somewhat bloat
the page count of this thesis.
Instead, we list the two ways to construct natural numbers: first,
\AgdaInductiveConstructor{zero} is a natural number.
Next, if you have a natural number, its successor
(\AgdaInductiveConstructor{suc}) is a natural number.

Agda has special syntax for constructing natural numbers: we can write
\AgdaNumber{3} instead of
\(\AgdaInductiveConstructor{suc}\;(\AgdaInductiveConstructor{suc}\;(\AgdaInductiveConstructor{suc}\;\AgdaInductiveConstructor{zero}))\).

There are several small pieces of information we'll need to understand in order
to write functions in Agda.
We'll go through them one by one.
\paragraph{Multi-Argument Functions}
Agda, like Haskell, doesn't really have a built-in notion of ``multi-argument''
functions.
Instead, multiple arguments are kind of simulated with \emph{currying}.

Here's how we define the addition of two natural numbers:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Nat.tex]{text-add}
\end{agdalisting*}
Instead of taking two \Nat s and returning a third, this function takes a
\Nat, and returns a function which takes a \Nat and returns a
\Nat.
\AgdaFunction{add}\;\AgdaNumber{0} returns a function which
adds \AgdaNumber{0} to a number; \AgdaFunction{add}\;\AgdaNumber{2} returns a
function which adds \AgdaNumber{2} to a number.
\paragraph{Operators}
Here's a function on the natural numbers:
\begin{agdalisting} \label{sub-def}
  \ExecuteMetaDataInline[agda/Snippets/Nat.tex]{sub-def}
\end{agdalisting}
We've defined subtraction.

Notice that this function is defined as an operator: for the function
declaration (the line with the type signature), we put underscores where we
expect the arguments to the operator to go.

We can also specify the precedence and fixity of the operator:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Nat.tex]{sub-fix}
\end{agdalisting*}
\paragraph{Total Functions}
In the introduction, we described Agda as a ``total'' programming language.
This means that if we give a function the type \(A \rightarrow B\), then we have
also \emph{proven} that, given an \(A\), it will produce a \(B\) (in finite
time).

Practically speaking, this means that Agda will perform some checks on our
code to ensure that every function is indeed total.
There are three checks that Agda performs that we will run into in this thesis:
coverage, termination, and productivity.
\subparagraph{Coverage}
This is the simplest check that Agda performs: it's also performed by GHC (if
\verb+-Wall+ is turned on).
This check ensures that functions are defined for all inputs.

Our definition of subtraction above (\Cref{sub-def}), for instance,
truncates to zero when there's arithmetic underflow.
In other words \(5 - 6 = 0\), according to our definition.
We could have removed the clause which allows for this:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Nat.tex]{bad-sub}
\end{agdalisting*}
But now the expression \(5 - 6\) is undefined.
\subparagraph{Termination}
The other major check that Agda will preform on our function definitions is for
\emph{termination} (or productivity, which we will see later).
This checks that no function we write accidentally contains an infinite loop.
Most of the time, we won't butt heads with the
termination checker, but it does happen occasionally, so it's helpful to
understand a little how it works. When we define the following function
(addition on the natural numbers):
\begin{agdalisting} \label{add-def}
  \ExecuteMetaDataInline[agda/Snippets/Nat.tex]{add-def}
\end{agdalisting}
Agda checks that the argument to the recursive call is \emph{structurally
  smaller} than the argument given to the outer function.
``Structurally smaller'' effectively means that the smaller thing must be a
subexpression of the larger: here, \(n\) is subexpression of
\(\AgdaInductiveConstructor{suc}\;n\).

Structural recursion is actually surprisingly powerful: a great many algorithms
can be converted to forms where the recursive calls recurse on some substructure
of their arguments.
It does require careful definitions, though.
For instance, the following will \emph{not} pass the termination checker:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Nat.tex]{bad-add}
\end{agdalisting*}
Though it defines the same function as \Cref{add-def}, it doesn't make
it absolutely obvious to the termination checker that the first argument to the
recursive call (\(n - 1\)) is structurally smaller than the outer argument
(\(n\)).

Occasionally a function can't be refactored to the extent where it will be
obviously structurally terminating to Agda.
In those cases, there are facilities to describe more complex termination
conditions (although we should stress that these facilities are not
built in to the compiler or anything: they're actually just extremely clever
ways to express structural recursion), but if you have to reach for those
facilities it's usually a sign you've gone wrong.
We won't use them here.
\subparagraph{Productivity}
Productivity isn't something we'll describe just yet, but we will give a hint as
to its purpose.
Often when describing total programming languages like Agda people make the
mistake of saying that they are ``not Turing complete''.
This is in fact not true, partly because Agda has the ability to describe non
terminating (and infinite) computations.
This allows us to implement, for instance, a Turing machine or
\(\lambda\)-calculus interpreter
\citep{mcbrideTuringCompletenessTotallyFree2015}, or more prosaic things like a
web server or repl.

While these things don't ``terminate'', Agda still needs to check that they are
valid with regards to computation in another sense.
This sense is \emph{productivity}: they need to always be able to produce
another piece of information in finite time, even if they never ``finish''
producing pieces of information.
\subparagraph{What's it all For?}
One thing we haven't answered is \emph{why} we bother checking for termination
or totality.
The answer is that it's necessary for Agda to be a valid proof assistant.
Imagine if we could construct a type for ``proofs of the Riemann hypothesis''.
We might call it \AgdaFunction{RiemannIsTrue}.
In a language like Haskell, the following is a completely valid program:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Nat.tex]{riemann-proof}
\end{agdalisting*}
But of course we \emph{haven't} provided a proof of the Riemann hypothesis (and
if we had we certainly wouldn't have buried the lead to this extent).
The termination checker is vital to rule out these kinds of ``proofs'': that's
why it's an integral part of Agda.
\subsection{An Expression Evaluator}
Let's put all of the different things we've learned into a more complex example.
We're going to write a small evaluator for arithmetic expressions.
Later, we'll use this to help us solve the Countdown problem
\citep{huttonCountdownProblem2002}.

We want to define a language of arithmetic expressions.
With countdown in mind, we'll only need to support four operators, which we can
define in a simple data type:
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{op-def}
\end{agdalisting}
Next, we'll define the actual type of expressions.
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{expr-def}
\end{agdalisting}
What we've defined here is actually a simple leafy binary tree.
The syntax for the second constructor is not so simple, however: it defines a
\emph{mixfix} operator.
Each underscore in \AgdaInductiveConstructor{\(\_\langle \_ \rangle\_\)}
represents a hole which expressions can be put into.
This allows us to use the constructor like so:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{example-expr}
\end{agdalisting*}

Evaluation of an expression is done by the following function:
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{incorrect-eval}
\end{agdalisting}
We've introduced the \AgdaKeyword{with} syntax here: it functions somewhat like
a case expression in Haskell.
Basically, it allows us to pattern-match on the result of applying a function to
one of the input arguments without defining a new function.
\subsection{Safe Evaluation With Maybe}
The evaluator we have written isn't exactly correct.
It implies things like \(4 - 5 = 0\), or \(10 \div 3 = 3\), or \(2 \div 0 = 0\);
this doesn't make the function ``wrong'' per se, but it might be more desirable
to have expressions like \(2 \div 0\) be undefined.
It's especially important for countdown, as division by zero (or any of the
other equations) isn't permitted.

To remedy the problem we're going to introduce a new type.
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Data/Maybe/Base.tex]{maybe-def}
\end{agdalisting}
\AgdaDatatype{Maybe} is a container that can contain at most one item.
It's the first \emph{parameterised} type we have seen: \AgdaDatatype{Maybe} can
contain an item of any type.
Here, for instance, is a \AgdaDatatype{Maybe} which contains the number 2:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Maybe.tex]{maybe-two}
\end{agdalisting*}
Or here is a \AgdaDatatype{Maybe} which doesn't contain anything, but whose type
says it could contain a function from \Nat to \Nat:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Maybe.tex]{maybe-nat-to-nat}
\end{agdalisting*}

Maybe is used often in functional programming to represent partiality: if you
have a function which is undefined for certain inputs, you can wrap
\AgdaDatatype{Maybe} around its return type, and return
\AgdaInductiveConstructor{nothing} for the cases where those inputs are given.
We can use it here, for instance, to define a version of subtraction which
doesn't truncate arithmetic underflow:
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{safe-sub}
\end{agdalisting}
It's often also used for similar purposes as \verb+null+ is in imperative
programming, although it is of course far safer since it's impossible to forget
to check for \AgdaInductiveConstructor{nothing} by definition.

We can use \AgdaDatatype{Maybe} in our evaluator for expressions, so that we
return \AgdaInductiveConstructor{nothing} on expressions which evaluate to
undefined values.
That changes the type to the following:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{eval-ty}
\end{agdalisting*}
The first case is relatively simple:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{lit-case}
\end{agdalisting*}

The second two cases are slightly more complex: the result of evaluating each
sub-tree is \(\AgdaDatatype{Maybe}\;\Nat\), not \Nat, so we will
have to pattern-match on the outputs to check for
\AgdaInductiveConstructor{nothing}.
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{add-helper}
\end{agdalisting*}
Code like this is quite tedious.
Luckily, there's a common pattern we can abstract out: whenever we have a
multi-argument function, we can apply it to arguments wrapped in
\AgdaDatatype{Maybe} using the following two functions.
\begin{multicols}{2} \null \vfill
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Data/Maybe/Sugar.tex]{pure}
  \end{agdalisting*} \vfill \null \columnbreak
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Data/Maybe/Sugar.tex]{ap}
  \end{agdalisting*}
\end{multicols} \noindent
Any type which implements these functions (in a certain law-abiding way) is said
to be an ``Applicative Functor''
\citep{mcbrideApplicativeProgrammingEffects2008}, a full explanation of which is
beyond the scope of this thesis.

It might not be immediately clear how those two functions can help us.
Basically, we can replace the \AgdaFunction{add-helper} function with the
following:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{add-helper-app}
\end{agdalisting*}
And, as it happens, Agda has special syntax which will automatically insert the
\AgdaFunction{pure} and \AgdaFunction{\_<*>\_} operators for us, making both the
addition and multiplication cases the following:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{appl-cases}
\end{agdalisting*}

Next, we have to handle subtraction.
In contrast to addition and multiplication, subtraction itself can produce a
\AgdaInductiveConstructor{nothing}: instead of having type
\(\Nat\rightarrow\Nat\rightarrow\Nat\), it has type 
\(\Nat\rightarrow\Nat\rightarrow\AgdaDatatype{Maybe}\;\Nat\).
To construct multi-argument functions of this particular type, we'll need
another function:
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Data/Maybe/Sugar.tex]{bind}
\end{agdalisting}
Types which implement this function (along with \AgdaFunction{pure}), modulo
some laws, are called Monads \citep{moggiNotionsComputationMonads1991a}.
This function will allow us to easily chain together several maybes even with
functions that return \AgdaDatatype{Maybe}.
It's used like this:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{sub-bind}
\end{agdalisting*}
And of course Agda also provides a syntax (do notation, just like Haskell) to
express the same:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{sub-case}
\end{agdalisting*}

Finally, we will handle the division case.
Here, we want to pattern-match on the returned value of the recursive call.
Agda also provides syntax for that:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{div-case}
\end{agdalisting*}
The \AgdaKeyword{where} keyword here lets us match on zero within the
\AgdaKeyword{do}-notation.
\subsection{Statically Proving the Evaluation is Safe}
Using this evaluator in practice can be a little annoying:
because it always returns a \AgdaDatatype{Maybe}, simple expressions which are
obviously valid still need to be checked at run-time.
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{example-eval}
\end{agdalisting*}
This is where Agda can add a little to the usual example for monads of an
expression evaluator: using dependent types, we can actually statically (and
automatically) prove that a given expression is valid, and evaluate it without
checking for \AgdaInductiveConstructor{nothing} safely.

First, we will need the following function:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{is-just}
\end{agdalisting*}
This simple function can tell us if the result of evaluating an expression is
successful or not.
In other words, it can test if an expression is valid.

To use this statically, however, we will need to employ the following
\emph{dependent} function:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{tee}
\end{agdalisting*}
This function turns our boolean values into types: \agdatop\;(tautology), or
\agdabot\;(impossibility).
These types are defined like so:
\begin{multicols}{2}
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{bot}
  \end{agdalisting*}  \columnbreak
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{top}
  \end{agdalisting*}
\end{multicols}
The first type here, \agdabot, has no constructors: there are no values which
inhabit the type \agdabot.
Logically speaking, it is the type of falsehoods.
It is quite useful in practice: any function of type \(A \rightarrow \agdabot\)
we know can never return, so we know that it must be impossible to call such a
function.
In other words, the type \(A\) must not have any values which inhabit it.
As such, we can use \agdabot\;to define a notion of ``not'' for types:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{not}
\end{agdalisting*}

The second type, \agdatop, is a \AgdaKeyword{record}.
Types defined using \AgdaKeyword{record} are quite like classes or structs
in an imperative programming language: instead of listing the constructors, we list
the \emph{fields} of these types.

Of course, in this case, our type doesn't have any fields.
Perhaps a more instructive example of a record is the following:
\begin{agdalisting} \label{pair-def}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{pair}
\end{agdalisting}
Here we've defined the type of \emph{pairs}.

Types defined with \AgdaKeyword{data} and types defined with
\AgdaKeyword{record} are in some sense duals of each other: to \emph{consume} a
\AgdaKeyword{data} type, we have to handle each of the constructors; to
\emph{construct} a \AgdaKeyword{record} type, we have to handle each of the
fields.
Another way to say this same thing is that \AgdaKeyword{data} types are sum
types, and \AgdaKeyword{record} types are products.
What we have in \agdabot\;and \agdatop\;is the identity for sums and products,
respectively.

Now, to be completely clear, we could absolutely have defined \agdatop\;as a
\AgdaKeyword{data} type with one constructor:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{data-top}
\end{agdalisting*}
We use the \AgdaKeyword{record} definition simply because it tends to work a
little better in terms of ergonomics: basically, to construct a
\AgdaKeyword{record} type automatically, Agda attempts to construct all of its
\emph{fields} one by one.
Since \agdatop\;has no fields, this is an easy task, and hence Agda will be able
to automatically construct a value of type \agdatop\;in many situations
(We can ask Agda to construct something for us automatically by supplying an
underscore in place of where the value should go).
Agda is more conservative about automatically constructing \AgdaKeyword{data}
types, so there are fewer situations where it will do it automatically.

So, now that we have a way of turning booleans into their logical equivalents
we can define a type for proofs that a given
expression is valid:
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{valid}
\end{agdalisting}
A value of type \(\AgdaFunction{Valid}\;e\), for some expression \(e\), is a
proof that \(e\) doesn't have (for example) any divisions by zero, or
arithmetic underflows.

Now we can write a function that takes an expression \(e\) and a proof that that
expression is valid; then, when we pattern-match on evaluating the expression
Agda will automatically rule out the case where it evaluates to
\AgdaInductiveConstructor{nothing}.
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{static-eval-explicit}
\end{agdalisting*}

A way to make calling this function a little cleaner (syntactically speaking) is
to use an implicit argument: 
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{static-eval}
\end{agdalisting*}
By surrounding the argument here in braces we are basically going to pass around
the argument invisibly and automatically (as much as is possible).
Though it's invisible, it's clearly still usable as a variable: in this case the
proof still rules out the clause where the evaluation returns
\AgdaInductiveConstructor{nothing}.
The real use of this feature, however, is that the argument is \emph{passed}
invisibly.
\begin{agdalisting} \label{example-static-eval}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{example-static-eval}
\end{agdalisting}
What's happened here is that the type of \(\AgdaFunction{Valid}\;e\) uniquely
determines one value: Agda can derive this, and it can also derive the value
determined.
As a result, it provides it automatically.
The precise rules for when Agda can ``provide something automatically'' are
actually a little tricky (it's quite important that we defined \agdatop\;as a
\AgdaKeyword{record}, for instance): a fuller explanation is available in the
Agda manual.

Two more things about implicit arguments: first, it is possible to retrieve an
argument even when it's supplied implicitly, with the following syntax:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{retrieve-implicit}
\end{agdalisting*}
Here we have bound the proof that the expression is valid to the variable
\AgdaBound{valid}.

Secondly, we have actually been using implicit arguments throughout the paper,
in combination with automatically generalised variables.
These two features are quite natural to most programmers (especially to
Haskellers), so it might come as a surprise that we've been using them, but it's
true.
Take the following definition of the identity function:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Implicits.tex]{id-def}
\end{agdalisting*}
This is the same function with all implicit arguments made explicit:
\begin{agdalisting} \label{id-expl}
  \ExecuteMetaDataInline[agda/Snippets/Implicits.tex]{id-expl}
\end{agdalisting}
We have hidden the universe level of the type (\(a\)) and the type itself
(\(A\)).

Furthermore, not only have we made these things implicit, we haven't actually
specified them in the type at all!
We're able to do this because at the top of our Agda file we say the following:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Level.tex]{level-var-decl}
\end{agdalisting*}
This \AgdaKeyword{variable} declaration means that if we ever refer to  \(A\) in
a function signature without defining it beforehand, Agda will automatically
insert the implicit arguments present in \Cref{id-expl}.
\subsection{Equalities}
We actually have encountered our first ``proof'' with dependent types: we have
proven that a given expression is valid or not.
Now we're going to look at another kind of proof: one that shows that an
expression is \emph{equal} to something.
To do so we'll first have to explore path types in Cubical Agda.
\begin{definition}[Path Types]
  A proof that two values are equal in Cubical Agda is represented by a
  \emph{path}.
  This path will be denoted with the symbol \AgdaFunction{\(\equiv\)}.
  In other words, a value of type \(x\;\AgdaFunction{\(\equiv\)}\;y\) is a proof
  that \(x\) equals \(y\).
\end{definition}

Equalities as paths is the first topic we have reached where Cubical Type Theory
begins to differ from traditional Martin-LÃ¶f Type Theory.
There, we would usually define the type of proofs of equality like so:
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Equality.tex]{equality-def}
\end{agdalisting}
This is an inductive \AgdaKeyword{data} type, with one constructor: the
constructor can only be used when the two parameters to the type are the same,
meaning a value of this type contains a proof that they are the same.
We can retrieve this proof by pattern-matching on that constructor.

This is actually a perfectly usable equality type in CuTT, although the
elimination rule is a little complex and we won't look into it just yet.
However we prefer to represent equalities in a slightly more primitive way, as
it turns out to be a little more flexible.
This is the \emph{path} representation.

When represented as a path, an equality between two values of type \(A\)
actually behaves more like a function from \AgdaDatatype{I} to \(A\).
\AgdaDatatype{I} here is the type of the interval: it ranges from
\AgdaInductiveConstructor{i0} to \AgdaInductiveConstructor{i1}.
So, as a function then, when the path \(x\;\AgdaFunction{\(\equiv\)}\;y\) is
applied to \AgdaInductiveConstructor{i0}, it returns \(x\), and when it is
applied to \AgdaInductiveConstructor{i1}, it returns \(y\).

\begin{marginfigure}
  \begin{tikzpicture}
    \node [anchor=base] at (-1.5 , 2.7) {$p :$};
    \node [anchor=base] at (-1   , 2.7) {$x$};
    \node [anchor=base] at ( 0   , 2.7) {\AgdaFunction{\(\equiv\)}};
    \node [anchor=base] at ( 1   , 2.7) {$y$};
    \node [anchor=base] at (-1.15, 2.1) {\footnotesize$p\;\AgdaFunction{i0} = x$};
    \node [anchor=base] at ( 0.85, 2.1) {\footnotesize$p\;\AgdaFunction{i1} = y$};
    \draw (-1,2.5) -- (1,2.5);
    \filldraw[black] (-1,2.5) circle (2pt);
    \filldraw[black] ( 1,2.5) circle (2pt);

    \node [anchor=base] at (-1.8, 0.2) {$\AgdaFunction{sym}\;p :$};
    \node [anchor=base] at (-1  , 0.2) {$y$};
    \node [anchor=base] at ( 0  , 0.2) {\AgdaFunction{\(\equiv\)}};
    \node [anchor=base] at ( 1  , 0.2) {$x$};
    \node [anchor=base] at (-1.4,-0.8) {\linespread{0}\footnotesize
      $\begin{aligned}
        \AgdaFunction{sym}\;p\;\AgdaFunction{i0} &= \\
        p\;(\AgdaOperator{\AgdaPrimitive{\textasciitilde{}}}\;\AgdaFunction{i0}) &= \\
        p\;\AgdaFunction{i1} &= y
      \end{aligned}$
    };
    \node [anchor=base] at ( 0.6,-0.8) {\linespread{0}\footnotesize
      $\begin{aligned}
        \AgdaFunction{sym}\;p\;\AgdaFunction{i1} &= \\
        p\;(\AgdaOperator{\AgdaPrimitive{\textasciitilde{}}}\;\AgdaFunction{i1}) &= \\
        p\;\AgdaFunction{i0} &= x
      \end{aligned}$
    };
    \draw (-1  ,0) -- ( 1,0);
    \filldraw[black] (-1,0) circle (2pt);
    \filldraw[black] (1,0) circle (2pt);

    \draw[-stealth] ( 1,2) to[out=-90, in=90] (-1,0.5);
    \draw[-stealth] (-1,2) to[out=-90, in=90] ( 1,0.5);
  \end{tikzpicture}
  \caption{Diagram of \(\AgdaFunction{sym}\;p\)}
  \label{sym-diagram}
\end{marginfigure}

Already we can manipulate paths in some interesting ways.
First, we can manipulate values in the interval: we can take the inverse of a
point in the interval, for instance.
It's worth thinking about what this ``inverse'' corresponds to in the equality:
we will name it in the next listing.
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Equality.tex]{sym-def}
\end{agdalisting*}
We will see some more intricate ways to manipulate paths later on, but for now
the ``function from an interval'' intuition is enough to understand the basics.

\subsection{Some Proofs of Equality}
So now that we know something about the equality type, let's put it to some use.
We can construct equality proofs of things which are ``obviously equal'' with
the following function:
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Equality.tex]{refl-def}
\end{agdalisting}
With this we can prove that the output from Equation.~\ref{example-static-eval}
is 8:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Expr.tex]{example-static-proof}
\end{agdalisting*}

Of course, these proofs aren't very interesting.
Something a little more complex might be the following:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Data/Nat/Properties.tex]{plus-assoc}
\end{agdalisting*}
Unfortunately we can't look at much more complex proofs without building up some
more machinery around path types: we can't currently compose paths, for
instance.
\subsection{Quotients}
We've seen that data types can be defined by listing their constructors, where
each constructor is just a function whose return type is the type being defined.
However, we've also seen that equalities are just functions from the interval.
If we combine these two notions, we can actually define a \emph{higher
  inductive} type.
\begin{definition}[Higher Inductive Type]
  A normal inductive type (like \AgdaDatatype{Bool}, or \Nat) is a type
  where its \emph{point} constructors are listed.
  A higher inductive type can have point constructors, but it can also have
  \emph{path} constructors: instead of adding new values to the type, these
  constructors add new equalities to the type.
\end{definition}

One of the nice aspects of CuTT is that higher inductive types arise naturally
from the ``function from an interval'' interpretation of path types.
Expand out the definition of \AgdaFunction{\(\equiv\)} in the following type,
for instance:
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Circle.tex]{circle-def}
\end{agdalisting}
We see that the \AgdaInductiveConstructor{loop} constructor, though odd looking,
still does represent a function whose return value is
\AgdaDatatype{\(\text{S}^1\)}.

Just with regards to this \AgdaDatatype{\(\text{S}^1\)} type: it's actually the
HoTT representation of the \emph{circle}.
We won't examine its more interesting properties all that much: however it is a
good example of the simplest type with complex homotopy, so we will use it to
demonstrate several HoTT principles.
\subsection{Basic Type Formers}
So far a lot of our descriptions of Agda have mixed Agda's type theory with its
syntax.
If this were a paper presenting the core type theory of Agda to an audience of
type theorists we probably would describe things in a slightly different way,
which has a lot less fancy syntax: we would instead present the core \emph{type
  formers} in Agda, and describe their semantics.
These type formers are basic types from which all other types can be built
(although it's usually much more ergonomic to use the syntax that we have been
using up until now: working with these type formers exclusively can feel a
little low-level at times).

We're going to explore them a little here: as the kind of basic subatomic
particles that make up every other type, they reveal a lot about the way types
work in general in Agda.
Also they can be useful in their own right: we've actually used all but one of
these types already.

The types \agdabot, \agdatop, and \AgdaDatatype{Bool} are three of the basic
type formers in MLTT.
Often they're called 0, 1, and 2; they're named for the number of elements which
inhabit them.

The next basic type is usually called \(\Pi\): it's the type of \emph{dependent
  functions}.
We've seen this type already, but here we should define it in a little more
depth.
\begin{definition}[Dependent Functions]
  A dependent function is one where the return type \emph{depends} on the value
  of the input.
  Here's a silly example:
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Formers.tex]{nat-or-string}
  \end{agdalisting*}
  When supplied with \AgdaInductiveConstructor{true}, the return type of this
  function is \Nat; when given \AgdaInductiveConstructor{false}, the
  return type is \AgdaDatatype{String}.
\end{definition}

Dependent functions are a built-in type in Agda, and they get the built-in
syntax that looks like the following:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{pi-syntax-2}
\end{agdalisting*}
If the \(A\) can be inferred, we could alternatively use the following syntax:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{pi-syntax-3}
\end{agdalisting*}
Finally, if we wanted to avoid syntactic sugar altogether, we can use the
\(\Pi\) symbol:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{pi-syntax-1}
\end{agdalisting*}
All three of these expressions denote the same type.

As the symbol suggests, \AgdaFunction{\(\Pi\)} types are \emph{product} types.
This might seem strange at first: a product type is usually a tuple,
i.e. the pair type we saw in \Cref{pair-def}.
As it happens, given the basic type formers we've defined so far, we can
actually make the pair type:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Formers.tex]{pair-def}
\end{agdalisting*}
This type has all the functions we might need on a standard pair:
\begin{multicols}{3}
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Formers.tex]{fst-def}
  \end{agdalisting*} \columnbreak
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Formers.tex]{snd-def}
  \end{agdalisting*} \columnbreak
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Formers.tex]{mk-pair}
  \end{agdalisting*}
\end{multicols}

Now that we have the type of dependent products, it's natural to ask if we have
a type for dependent sums.
This is a type we \emph{haven't} seen before, although we have all the pieces
needed to define it.
\begin{definition}[The Dependent Sum]
  Dependent sums are denoted with the usual \(\Sigma\) symbol, and has the
  following definition in Agda:
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{sigma}
  \end{agdalisting*}
  The dependent sum is like the constructive version of the existential
  quantifier: the expression \(\AgdaDatatype{\(\Sigma\)}\;A\;B\) can be
  interpreted as ``there exists an \(A\) such that \(B\)''.
\end{definition}

There are a number of different syntactic ways to express
\(\AgdaDatatype{\(\Sigma\)}\;A\;B\).
The following are all equivalent:
\begin{multicols}{4}
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{sigma-syntax-1}
  \end{agdalisting*} \columnbreak
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{sigma-syntax-3}
  \end{agdalisting*} \columnbreak
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{sigma-syntax-4}
  \end{agdalisting*} \columnbreak
  \begin{agdalisting*}
    \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{sigma-syntax-2}
  \end{agdalisting*}
\end{multicols} \vspace{-1\baselineskip}

Though we have shown that the dependent function type is suitable as a pair
type, \AgdaDatatype{\(\Sigma\)} is actually a little easier to use as our basic
pair type.
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Formers.tex]{pair-sigma}
\end{agdalisting}
So how, then, is \AgdaDatatype{\(\Sigma\)} a sum type?
Sum types in non-dependent type theory are the disjoint unions:
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{disj-union}
\end{agdalisting}
It turns out that we can actually use a quite similar trick to how we got the
pair from \AgdaDatatype{\(\Pi\)}:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Introduction.tex]{sigma-disj-union}
\end{agdalisting*}
\subsection{The Menagerie of Foundational Theories}
So far we have mentioned four different foundational theories: Martin-LÃ¶f Type
Theory, Homotopy Type Theory, Cubical Type Theory, and Zermelo-Fraenkel set theory.
We have given some hints as to the differences between these theories, but now
We have enough background information to give a fuller explanation as to their
difference and historical context.

Firstly we have Zermelo-Fraenkel set theory, or ZFC, where the C stands for
``choice'', i.e. the axiom of choice.
This is the standard foundational system for most mathematics these days: it's a
set theoretic foundation, and it's \emph{classical}, by which we mean
non-constructive.
This means that it has the law of the excluded middle (for any given
proposition, the proposition is either true or false), and the axiom of choice
(the product of a collection of non-empty sets is non-empty).

We won't describe ZFC in much detail here, we only mention it to contrast it
with type theory.
Type theory is less extensional than set theory: in set theory we construct sets
by saying which things they contain.
These things exist ambiently, independent of the set (or sets) which contain
them.
To define the set of the natural numbers, for example, we first need there to
exist objects which represent each of the numbers. 
Before defining \(\mathbb{N}\), we need to have defined 1 and 2.

Type theory is quite different in this sense.
The analogous construct to the set (the type) constructs its contents in its
definition.
So the type of the natural numbers contains the definition (or construction) of
its contents.
It doesn't make sense to define a type which contains items in other types: in
fact it's not possible.

So that is the difference in mechanics between type theory and set theory: other
than the non-constructive components of set theory, though, the two theories are
equivalent.

Within type theory then we have three different systems: MLTT, HoTT, and CuTT
(of course there are many more type theories than just these three: these are
only the theories we will study here).
The first of these was one of the first type theories to be defined: Per
Martin-LÃ¶f's intuitionistic type theory
\citep{martin-lofIntuitionisticTypeTheory1980} defined the basics of dependent
types as we use them in Agda today.
This early theory had the \(\Sigma\) and \(\Pi\) types we have above, as
well as the boolean types, and \(\top\) and \(\bot\).
With some changes to the system (the addition of universe levels prompted by
Girard's paradox), it's basically the core of Agda today.

HoTT \citep{hottbook} is a type theory which stems in many ways from MLTT, but
mixes it with homotopy theory.
The fundamental addition of HoTT is the univalence axiom, which allows for
isomorphic types to be treated as equivalent.
CuTT \citep{cohenCubicalTypeTheory2016} is closely related to HoTT: it is the
theory which allows us to use univalence in Agda while retaining the
computational properties that we would expect in a constructive system.
\subsection{Comparing Classical And Constructive Proofs in Agda}
The dependent sum is a great example of the difference between ``classical'' and
``constructive'' mathematics: the closest analogue in classical mathematics to
\AgdaDatatype{\(\Sigma\)} is \(\exists\), but the semantics of the two
constructs are subtly different.
If I say ``there exists an integer larger than 10'' I'm making a rather
trivially true statement; to provide a proof that
\(\AgdaDatatype{\(\Sigma\)}\;\Nat\;\lambda\;\AgdaBound{n}\rightarrow
\AgdaNumber{10}\;\AgdaFunction{<}\;\AgdaBound{n}\) is more akin to providing a
natural number, and proving that it's bigger than 10.

More formally speaking, there are a number of axioms which we don't have access
to constructively.
One such axiom is double negation elimination:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Classical.tex]{doubleneg-elim}
\end{agdalisting*}
One way to ``do'' classical mathematics within Agda, then, would be to write all
of the proofs assuming these axioms.
We don't have to break the guarantees Agda provides, either: we could say
``given the axiom of choice, law of the excluded middle, etc., the following is
true\textellipsis'', although this is a little clunky.

Instead, using this axiom of double negation, we can actually provide a type for
classical computation.
\begin{agdalisting}
  \ExecuteMetaDataInline[agda/Snippets/Classical.tex]{classical-def}
\end{agdalisting}
In the ``propositions-as-types'' sense, a value of type
\(\AgdaFunction{Classical}\;A\) is a classical proof of the proposition \(A\).
This translation between classical and constructive proofs using double negation
is sometimes called the double-negation translation.

We can prove, inside this type, things like the law of the excluded middle:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Classical.tex]{lem-proof}
\end{agdalisting*}
This type forms a monad, meaning that it implements the following functions:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Classical.tex]{monad}
\end{agdalisting*}
This gives us a convenient syntax to work with classical proofs.

Finally, in HoTT we have a notion of \emph{stability}.
Certain types do support double-negation elimination:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Relation/Nullary/Stable.tex]{stable-def}
\end{agdalisting*}
We will see a use for this notion later on, but we mention it here to point out
that we do have a way of describing types which can be pulled out of classical
proofs.

The purpose of this last subsection was to demonstrate that constructive
mathematics, far from being constrained in comparison to classical, are
technically \emph{more} capable.
We can actually use systems to Agda to check and verify classical proofs just as
much as we can constructive.
\subsection{Computational Behaviour}
Up until this point we have been suspiciously quiet on the issue of performance
or efficiency.
While everything we're doing is absolutely valid as a purely theoretical
exercise, it is nonetheless interesting to ask what these proofs and programs
perform like on a computer.

The first thing to note is that Agda is a \emph{lazy} language.
This means that expressions are not evaluated until they're needed.
Take the following function:
\begin{agdalisting*}
  \ExecuteMetaDataInline[agda/Snippets/Complexity.tex]{f-def}
\end{agdalisting*}
Since this function ignores its argument, Agda won't \emph{compute} its
argument.
If we called, for instance,
\(\AgdaFunction{f}\;(\AgdaNumber{1000}\;\AgdaFunction{+}\;\AgdaNumber{1000})\),
we wouldn't ever have to pay the cost of computing
\(\AgdaNumber{1000}\;\AgdaFunction{+}\;\AgdaNumber{1000}\).

It's important to note that this difference in performance is usually \emph{not}
observable in actual computation.
Unless we are working with coinductive types (which we will not do in this
thesis), Agda's semantics are agnostic as to evaluation strategy.
A program that terminates with lazy evaluation will also terminate with strict.
It's just that one might take a much longer (but still finite!) amount of time
to do so.

The second thing to note is that, in order to make proofs easier, we often work
with inefficient forms of certain data types.
The natural numbers, for instance, we represent as basically a singly-linked
list; there are no flat arrays to be found anywhere in Agda; and recursion
(albeit tail-call optimised recursion) is the tool of choice for iterative
computation.
There is some help: in certain cases Agda will optimise the natural numbers to
actual binary numbers (arbitrary precision Haskell integers), and Agda's purity
allows for a certain degree of optimisation.
Overall, though, unfortunately Agda is quite slow.
Computing an expression like \(\AgdaBound{n}\;\AgdaFunction{+}\;\AgdaBound{m}\)
will usually take \(\mathcal{O}(\AgdaBound{n})\) time, and there's not really a
great way to get around it.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper"
%%% End:
